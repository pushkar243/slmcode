{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f8a8526ed7b54c5482e95178a44f643a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_586498e4cf3946d88289b142a8e9e83c",
              "IPY_MODEL_371c037351294c5b8e273bbd4f82e216",
              "IPY_MODEL_6d30127f4d4a4cdcbc92ffe5d9c356ae"
            ],
            "layout": "IPY_MODEL_c8c9efacbcdd4e2b9d08d4d8e72df8b7"
          }
        },
        "586498e4cf3946d88289b142a8e9e83c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7fb0de0e85f4462f8d8d7569ea3a6276",
            "placeholder": "​",
            "style": "IPY_MODEL_ada47175c49740e8882d37c2ea46f29f",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "371c037351294c5b8e273bbd4f82e216": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbf52285495b4612889ef6845a1aa3bd",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0cb49f49cca54a9088538696ae9cf487",
            "value": 2
          }
        },
        "6d30127f4d4a4cdcbc92ffe5d9c356ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e9fbd363ede4c58923ac75d87a7c9d2",
            "placeholder": "​",
            "style": "IPY_MODEL_a012cf648a1e4e5fbea5d8c2f3e3f24f",
            "value": " 2/2 [00:31&lt;00:00, 14.68s/it]"
          }
        },
        "c8c9efacbcdd4e2b9d08d4d8e72df8b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fb0de0e85f4462f8d8d7569ea3a6276": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ada47175c49740e8882d37c2ea46f29f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fbf52285495b4612889ef6845a1aa3bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cb49f49cca54a9088538696ae9cf487": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1e9fbd363ede4c58923ac75d87a7c9d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a012cf648a1e4e5fbea5d8c2f3e3f24f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# SANITY: Generate 50 educational Q/A from PDFs (Colab cell)\n",
        "# -------------------------\n",
        "# Paste this into one Colab cell and run.\n",
        "# Make sure: Runtime -> GPU (T4). Upload PDFs to /content/pdfs/ or change PDF_FOLDER.\n",
        "\n",
        "# Install minimal required libs (skip if already installed)\n",
        "!pip install -q transformers pypdf sentence-transformers accelerate\n",
        "\n",
        "# ---------- Config ----------\n",
        "PDF_FOLDER = \"/content/drive/MyDrive/content/pdfs\"            # change if your PDFs are on Drive\n",
        "DRIVE_SAVE_DIR = \"/content/drive/MyDrive/mistral_pipeline\"  # optional\n",
        "QA_COUNT_TARGET = 50                   # you requested 50\n",
        "PAIRS_PER_CHUNK = 1                    # produce 1 Q/A per chunk to control quality\n",
        "CHUNK_SIZE = 800\n",
        "CHUNK_OVERLAP = 120\n",
        "GEN_MODEL = \"google/gemma-2b-it\"       # educational style prompt tuned below\n",
        "DEVICE = \"cuda\"                        # ensure GPU runtime\n",
        "\n",
        "# ---------- Mount Drive (optional) ----------\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "import os, re, json, csv, time\n",
        "from pathlib import Path\n",
        "pdf_dir = Path(PDF_FOLDER)\n",
        "os.makedirs(DRIVE_SAVE_DIR, exist_ok=True)\n",
        "\n",
        "# ---------- 1) Extract pages from PDFs ----------\n",
        "from pypdf import PdfReader\n",
        "pages = []   # each element: {file,page,text}\n",
        "if not pdf_dir.exists():\n",
        "    raise SystemExit(f\"PDF folder {PDF_FOLDER} not found. Upload PDFs there or change PDF_FOLDER.\")\n",
        "\n",
        "for fp in sorted(pdf_dir.glob(\"*.pdf\")):\n",
        "    try:\n",
        "        r = PdfReader(str(fp))\n",
        "        for i, p in enumerate(r.pages):\n",
        "            txt = p.extract_text() or \"\"\n",
        "            txt = re.sub(r\"\\s+\", \" \", txt).strip()\n",
        "            if len(txt) > 80:\n",
        "                pages.append({\"file\": fp.name, \"page\": i+1, \"text\": txt})\n",
        "    except Exception as e:\n",
        "        print(\"Error reading\", fp.name, \":\", e)\n",
        "\n",
        "print(\"Pages extracted:\", len(pages))\n",
        "if len(pages) == 0:\n",
        "    raise SystemExit(\"No PDF text found. Are PDFs scanned images? Use OCR first.\")\n",
        "\n",
        "# ---------- 2) Chunk pages into manageable pieces ----------\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP)\n",
        "chunks = []\n",
        "for p in pages:\n",
        "    parts = splitter.split_text(p[\"text\"])\n",
        "    for idx, part in enumerate(parts):\n",
        "        chunks.append({\"chunk_id\": f\"{p['file']}_p{p['page']}_c{idx}\",\n",
        "                       \"file\": p[\"file\"], \"page\": p[\"page\"], \"text\": part})\n",
        "print(\"Chunks created:\", len(chunks))\n",
        "\n",
        "# ---------- 3) Load generator (Gemma 2B) ----------\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "\n",
        "generator = None\n",
        "tokenizer_gen = None\n",
        "\n",
        "def try_load_gen(model_name):\n",
        "    try:\n",
        "        t = AutoTokenizer.from_pretrained(model_name, trust_remote_code=False, use_fast=True)\n",
        "        m = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\", torch_dtype=torch.float16)\n",
        "        return t, m\n",
        "    except Exception as e:\n",
        "        print(\"Load failed for\", model_name, \":\", e)\n",
        "        return None, None\n",
        "\n",
        "print(\"Attempting to load generator:\", GEN_MODEL)\n",
        "tokenizer_gen, model_gen = try_load_gen(GEN_MODEL)\n",
        "\n",
        "if tokenizer_gen is None or model_gen is None:\n",
        "    # fallback: use a very small HF model if gemma is not available\n",
        "    fallback = \"microsoft/phi-3-mini-4k-instruct\"\n",
        "    print(\"Falling back to\", fallback)\n",
        "    tokenizer_gen, model_gen = try_load_gen(fallback)\n",
        "    if tokenizer_gen is None:\n",
        "        raise SystemExit(\"No generator available. Upload a local GGUF or ensure HF access.\")\n",
        "\n",
        "gen_device = next(model_gen.parameters()).device\n",
        "print(\"Generator loaded on\", gen_device)\n",
        "\n",
        "# ---------- 4) Educational-style prompt template ----------\n",
        "PROMPT_TEMPLATE = \"\"\"You are a helpful subject-matter expert. Read the text below and generate ONE clear, educational question followed by a concise, explanation-rich answer.\n",
        "Only use facts present in the text. Do NOT add outside information. Use complete sentences and an explanatory tone (suitable for teaching a colleague).\n",
        "\n",
        "Text:\n",
        "\\\"\\\"\\\"\n",
        "{chunk}\n",
        "\\\"\\\"\\\"\n",
        "\n",
        "Return exactly in this format:\n",
        "\n",
        "Q: <question>\n",
        "A: <answer>\n",
        "\"\"\"\n",
        "\n",
        "# ---------- 5) Generate Q/A pairs (stop when we reach QA_COUNT_TARGET) ----------\n",
        "raw_qas = []\n",
        "processed = 0\n",
        "# We'll iterate through chunks in order — stop after collecting QA_COUNT_TARGET pairs\n",
        "for ch in chunks:\n",
        "    if processed >= QA_COUNT_TARGET:\n",
        "        break\n",
        "    prompt = PROMPT_TEMPLATE.format(chunk=ch[\"text\"])\n",
        "    try:\n",
        "        inputs = tokenizer_gen(prompt, return_tensors=\"pt\", truncation=True, max_length=2048).to(model_gen.device)\n",
        "        gen = model_gen.generate(**inputs, max_new_tokens=256, do_sample=False)\n",
        "        out_text = tokenizer_gen.decode(gen[0], skip_special_tokens=True)\n",
        "    except Exception as e:\n",
        "        print(\"Generation error for chunk\", ch[\"chunk_id\"], \":\", e)\n",
        "        continue\n",
        "\n",
        "    # parse Q/A\n",
        "    if \"Q:\" in out_text and \"A:\" in out_text:\n",
        "        try:\n",
        "            q = out_text.split(\"Q:\", 1)[1].split(\"A:\",1)[0].strip()\n",
        "            a = out_text.split(\"A:\",1)[1].strip()\n",
        "            if len(q) > 3 and len(a) > 10:   # simple filters\n",
        "                raw_qas.append({\"question\": q, \"answer\": a, \"chunk_id\": ch[\"chunk_id\"], \"file\": ch[\"file\"], \"page\": ch[\"page\"]})\n",
        "                processed += 1\n",
        "        except Exception as e:\n",
        "            # fallback naive parse\n",
        "            lines = [ln.strip() for ln in out_text.splitlines() if ln.strip()]\n",
        "            q=None; a=None\n",
        "            for ln in lines:\n",
        "                if ln.lower().startswith(\"q:\"):\n",
        "                    q = ln.split(\":\",1)[1].strip()\n",
        "                elif ln.lower().startswith(\"a:\"):\n",
        "                    a = ln.split(\":\",1)[1].strip()\n",
        "                    if q and a:\n",
        "                        raw_qas.append({\"question\": q, \"answer\": a, \"chunk_id\": ch[\"chunk_id\"], \"file\": ch[\"file\"], \"page\": ch[\"page\"]})\n",
        "                        processed += 1\n",
        "                        q=None; a=None\n",
        "    else:\n",
        "        # If output doesn't have Q/A markers, try heuristics\n",
        "        text = out_text.strip()\n",
        "        # find first question-like sentence (ends with '?') and following sentence(s)\n",
        "        import re\n",
        "        m = re.search(r'([A-Z][^?!.]{10,}\\?)', text)\n",
        "        if m:\n",
        "            q = m.group(1).strip()\n",
        "            rest = text[m.end():].strip()\n",
        "            a = rest.split(\"\\n\",1)[0].strip() if rest else \"\"\n",
        "            if q and a:\n",
        "                raw_qas.append({\"question\": q, \"answer\": a, \"chunk_id\": ch[\"chunk_id\"], \"file\": ch[\"file\"], \"page\": ch[\"page\"]})\n",
        "                processed += 1\n",
        "\n",
        "    # small throttle\n",
        "    time.sleep(0.12)\n",
        "\n",
        "print(f\"Generated {len(raw_qas)} Q/A pairs (target was {QA_COUNT_TARGET})\")\n",
        "\n",
        "# ---------- 6) Persist qna_dataset.csv and copy to Drive ----------\n",
        "import shutil\n",
        "OUT_CSV = \"qna_dataset.csv\"\n",
        "with open(OUT_CSV, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"question\",\"answer\",\"chunk_id\",\"file\",\"page\"])\n",
        "    for r in raw_qas:\n",
        "        writer.writerow([r[\"question\"], r[\"answer\"], r[\"chunk_id\"], r[\"file\"], r[\"page\"]])\n",
        "print(\"Saved:\", OUT_CSV)\n",
        "# copy to drive\n",
        "shutil.copy(OUT_CSV, os.path.join(DRIVE_SAVE_DIR, OUT_CSV))\n",
        "print(\"Copied to Drive:\", os.path.join(DRIVE_SAVE_DIR, OUT_CSV))\n",
        "\n",
        "# ---------- 7) Token-length sanity checks (using the generator tokenizer) ----------\n",
        "from statistics import mean\n",
        "q_lens = [len(tokenizer_gen.encode(r[\"question\"])) for r in raw_qas]\n",
        "a_lens = [len(tokenizer_gen.encode(r[\"answer\"])) for r in raw_qas]\n",
        "print(\"Questions: count\", len(q_lens), \"avg tokens\", mean(q_lens) if q_lens else 0, \"max\", max(q_lens) if q_lens else 0)\n",
        "print(\"Answers:   count\", len(a_lens), \"avg tokens\", mean(a_lens) if a_lens else 0, \"max\", max(a_lens) if a_lens else 0)\n",
        "\n",
        "# ---------- 8) Show 10 samples for manual QA ----------\n",
        "import pandas as pd\n",
        "df = pd.read_csv(OUT_CSV)\n",
        "print(\"\\n=== 10 sample Q/A (manual inspection) ===\")\n",
        "display(df.sample(min(10, len(df))).reset_index(drop=True))\n",
        "\n",
        "# ---------- 9) Short automated checks ----------\n",
        "# - ensure at least 10 Q/A were generated\n",
        "# - basic heuristic: answer must contain at least one noun from chunk (quick check)\n",
        "def quick_quality_check(df, chunks_map, min_pairs=10):\n",
        "    issues=[]\n",
        "    if len(df) < min_pairs:\n",
        "        issues.append(f\"Too few Q/A pairs: {len(df)} < {min_pairs}\")\n",
        "    # check small % of answers contain words from their source chunk\n",
        "    ok_count=0; total=0\n",
        "    for i, row in df.sample(min(20,len(df))).iterrows():\n",
        "        total += 1\n",
        "        src = chunks_map.get(row['chunk_id'],\"\")\n",
        "        # look for overlap of 3+ characters words\n",
        "        overlap = 0\n",
        "        for tok in re.findall(r'\\\\w{4,}', row['answer'].lower()):\n",
        "            if tok in src.lower():\n",
        "                overlap += 1\n",
        "            if overlap >= 1:\n",
        "                ok_count += 1\n",
        "                break\n",
        "    if total>0:\n",
        "        pct = ok_count/total\n",
        "        if pct < 0.3:\n",
        "            issues.append(f\"Low contextual overlap in sample ({ok_count}/{total} ≈ {pct:.2f})\")\n",
        "    return issues\n",
        "\n",
        "# build chunk map\n",
        "chunk_map = {c['chunk_id']: c['text'] for c in chunks}\n",
        "issues = quick_quality_check(df, chunk_map, min_pairs=10)\n",
        "print(\"Quick quality check issues:\", issues if issues else \"None detected\")\n",
        "\n",
        "print(\"\\nSanity step done. If samples look good, reply 'Dataset Ready ✅' and I will give the optimized training pipeline next.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 776,
          "referenced_widgets": [
            "f8a8526ed7b54c5482e95178a44f643a",
            "586498e4cf3946d88289b142a8e9e83c",
            "371c037351294c5b8e273bbd4f82e216",
            "6d30127f4d4a4cdcbc92ffe5d9c356ae",
            "c8c9efacbcdd4e2b9d08d4d8e72df8b7",
            "7fb0de0e85f4462f8d8d7569ea3a6276",
            "ada47175c49740e8882d37c2ea46f29f",
            "fbf52285495b4612889ef6845a1aa3bd",
            "0cb49f49cca54a9088538696ae9cf487",
            "1e9fbd363ede4c58923ac75d87a7c9d2",
            "a012cf648a1e4e5fbea5d8c2f3e3f24f"
          ]
        },
        "id": "FfL5cHkaTSml",
        "outputId": "02eb795d-565b-4522-e23b-1e809c844879"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Pages extracted: 2054\n",
            "Chunks created: 6951\n",
            "Attempting to load generator: google/gemma-2b-it\n",
            "Load failed for google/gemma-2b-it : You are trying to access a gated repo.\n",
            "Make sure to have access to it at https://huggingface.co/google/gemma-2b-it.\n",
            "401 Client Error. (Request ID: Root=1-690a55a5-2a9c061c7976500a206351f4;e17b68f7-9d3d-40d0-9385-5727f3920f9b)\n",
            "\n",
            "Cannot access gated repo for url https://huggingface.co/google/gemma-2b-it/resolve/main/config.json.\n",
            "Access to model google/gemma-2b-it is restricted. You must have access to it and be authenticated to access it. Please log in.\n",
            "Falling back to microsoft/phi-3-mini-4k-instruct\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f8a8526ed7b54c5482e95178a44f643a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generator loaded on cuda:0\n",
            "Generated 50 Q/A pairs (target was 50)\n",
            "Saved: qna_dataset.csv\n",
            "Copied to Drive: /content/drive/MyDrive/mistral_pipeline/qna_dataset.csv\n",
            "Questions: count 50 avg tokens 3 max 3\n",
            "Answers:   count 50 avg tokens 256.78 max 260\n",
            "\n",
            "=== 10 sample Q/A (manual inspection) ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     question                                             answer  \\\n",
              "0  <question>  <answer>\\n\\nQuestion:\\nWhat are the notational...   \n",
              "1  <question>  <answer>\\n\\nQuestion:\\nWhat is the purpose of ...   \n",
              "2  <question>  <answer>\\n\\nQuestion:\\nHow does Manning's syst...   \n",
              "3  <question>  <answer>\\n\\nQ: What is the purpose of performi...   \n",
              "4  <question>  <answer>\\n\\nQ: What is the focus of Chapter 5 ...   \n",
              "5  <question>  <answer>\\n\\nQuestion: What is the relationship...   \n",
              "6  <question>  <answer>\\n\\nQuestion:\\nWhat are the main topic...   \n",
              "7  <question>  <answer>\\n\\nQuestion: What is the relationship...   \n",
              "8  <question>  <answer>\\n\\nQ: What is the ISBN number for the...   \n",
              "9  <question>  <answer>\\n\\nQuestion:\\nWhat does the notation ...   \n",
              "\n",
              "                                            chunk_id  \\\n",
              "0  Foundations of Statistical Natural Language Pr...   \n",
              "1  Foundations of Statistical Natural Language Pr...   \n",
              "2  Foundations of Statistical Natural Language Pr...   \n",
              "3  Foundations of Statistical Natural Language Pr...   \n",
              "4  Foundations of Statistical Natural Language Pr...   \n",
              "5  Foundations of Statistical Natural Language Pr...   \n",
              "6  Foundations of Statistical Natural Language Pr...   \n",
              "7  Foundations of Statistical Natural Language Pr...   \n",
              "8  Foundations of Statistical Natural Language Pr...   \n",
              "9  Foundations of Statistical Natural Language Pr...   \n",
              "\n",
              "                                                file  page  \n",
              "0  Foundations of Statistical Natural Language Pr...    15  \n",
              "1  Foundations of Statistical Natural Language Pr...    16  \n",
              "2  Foundations of Statistical Natural Language Pr...    14  \n",
              "3  Foundations of Statistical Natural Language Pr...    19  \n",
              "4  Foundations of Statistical Natural Language Pr...     3  \n",
              "5  Foundations of Statistical Natural Language Pr...     5  \n",
              "6  Foundations of Statistical Natural Language Pr...    14  \n",
              "7  Foundations of Statistical Natural Language Pr...    21  \n",
              "8  Foundations of Statistical Natural Language Pr...     2  \n",
              "9  Foundations of Statistical Natural Language Pr...    22  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f4c89ddd-a9df-45e9-9978-15e2b950f66b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>chunk_id</th>\n",
              "      <th>file</th>\n",
              "      <th>page</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;question&gt;</td>\n",
              "      <td>&lt;answer&gt;\\n\\nQuestion:\\nWhat are the notational...</td>\n",
              "      <td>Foundations of Statistical Natural Language Pr...</td>\n",
              "      <td>Foundations of Statistical Natural Language Pr...</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;question&gt;</td>\n",
              "      <td>&lt;answer&gt;\\n\\nQuestion:\\nWhat is the purpose of ...</td>\n",
              "      <td>Foundations of Statistical Natural Language Pr...</td>\n",
              "      <td>Foundations of Statistical Natural Language Pr...</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&lt;question&gt;</td>\n",
              "      <td>&lt;answer&gt;\\n\\nQuestion:\\nHow does Manning's syst...</td>\n",
              "      <td>Foundations of Statistical Natural Language Pr...</td>\n",
              "      <td>Foundations of Statistical Natural Language Pr...</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;question&gt;</td>\n",
              "      <td>&lt;answer&gt;\\n\\nQ: What is the purpose of performi...</td>\n",
              "      <td>Foundations of Statistical Natural Language Pr...</td>\n",
              "      <td>Foundations of Statistical Natural Language Pr...</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>&lt;question&gt;</td>\n",
              "      <td>&lt;answer&gt;\\n\\nQ: What is the focus of Chapter 5 ...</td>\n",
              "      <td>Foundations of Statistical Natural Language Pr...</td>\n",
              "      <td>Foundations of Statistical Natural Language Pr...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>&lt;question&gt;</td>\n",
              "      <td>&lt;answer&gt;\\n\\nQuestion: What is the relationship...</td>\n",
              "      <td>Foundations of Statistical Natural Language Pr...</td>\n",
              "      <td>Foundations of Statistical Natural Language Pr...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>&lt;question&gt;</td>\n",
              "      <td>&lt;answer&gt;\\n\\nQuestion:\\nWhat are the main topic...</td>\n",
              "      <td>Foundations of Statistical Natural Language Pr...</td>\n",
              "      <td>Foundations of Statistical Natural Language Pr...</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>&lt;question&gt;</td>\n",
              "      <td>&lt;answer&gt;\\n\\nQuestion: What is the relationship...</td>\n",
              "      <td>Foundations of Statistical Natural Language Pr...</td>\n",
              "      <td>Foundations of Statistical Natural Language Pr...</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>&lt;question&gt;</td>\n",
              "      <td>&lt;answer&gt;\\n\\nQ: What is the ISBN number for the...</td>\n",
              "      <td>Foundations of Statistical Natural Language Pr...</td>\n",
              "      <td>Foundations of Statistical Natural Language Pr...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>&lt;question&gt;</td>\n",
              "      <td>&lt;answer&gt;\\n\\nQuestion:\\nWhat does the notation ...</td>\n",
              "      <td>Foundations of Statistical Natural Language Pr...</td>\n",
              "      <td>Foundations of Statistical Natural Language Pr...</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f4c89ddd-a9df-45e9-9978-15e2b950f66b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f4c89ddd-a9df-45e9-9978-15e2b950f66b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f4c89ddd-a9df-45e9-9978-15e2b950f66b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-84d6c745-13f6-4449-9232-2cac879109a7\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-84d6c745-13f6-4449-9232-2cac879109a7')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-84d6c745-13f6-4449-9232-2cac879109a7 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"\\\\nSanity step done\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"<question>\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"<answer>\\n\\nQ: What is the ISBN number for the book \\\"Computational Linguistics-Statistical Methods\\\" by Hinrich Schutze?\\nA: The ISBN number for the book \\\"Computational Linguistics-Statistical Methods\\\" by Hinrich Schutze is 0-262-13360-l. This unique identifier is used internationally to identify books and other publications. It consists of 13 digits, with the first three representing the publisher, the next five the country, the next one the publisher's location, and the last four the specific edition of the book. In this case, the publisher is represented by the first three digits (0-262), the country by the next five (13360), and the publisher's location by the last digit (l). The remaining digits (0-26213360) are unique to this specific edition of the book.\\n\\nQ: What are the classification numbers for the book \\\"Computational Linguistics-Statistical Methods\\\" by Hinrich Schutze?\\nA: The classification numbers for the book \\\"Computational Linguistics-Stat\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chunk_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Foundations of Statistical Natural Language Processing, Manning and Schu\\u0308tze, MIT Press. Cambridge, MA.pdf_p2_c1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"file\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Foundations of Statistical Natural Language Processing, Manning and Schu\\u0308tze, MIT Press. Cambridge, MA.pdf\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"page\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7,\n        \"min\": 2,\n        \"max\": 22,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quick quality check issues: ['Low contextual overlap in sample (0/20 ≈ 0.00)']\n",
            "\n",
            "Sanity step done. If samples look good, reply 'Dataset Ready ✅' and I will give the optimized training pipeline next.\n"
          ]
        }
      ]
    }
  ]
}